import numpy as np 
import matplotlib.pyplot as plt

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization

# CNN model
model = Sequential()
# The first two layers with 32 filters of window size 3x3
model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(300, 300, 3)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))

# Normalizes the network input weights between 0 and 1
model.add(BatchNormalization())

model.add(Dense(8, activation='softmax'))

model.compile(
    optimizer='adam', 
    loss='categorical_crossentropy', 
    metrics=['acc']
)

import time
from keras.preprocessing.image import ImageDataGenerator

# Defines the Data Augmentation
train_datagen = ImageDataGenerator(
    rescale = 1./255,
    shear_range = 0.2,
    zoom_range = 0.2,
)

test_datagen = ImageDataGenerator(
    rescale = 1./255
)

training_set = train_datagen.flow_from_directory(
    'dataset/training_set',
    target_size = (300, 300),
    batch_size = 1,
    class_mode = 'categorical'
)

test_set = test_datagen.flow_from_directory(
    'dataset/test_set',
    target_size = (300, 300),
    batch_size = 1,
    class_mode = 'categorical'
)

epochs = 32

start = time.time()
# Fit the model on the batches generated by datagen.flow().
history = model.fit_generator(
    training_set,
    steps_per_epoch = len(training_set),
    epochs = epochs,
    validation_data = test_set,
    validation_steps = len(test_set)
)

end = time.time()

model.save('results/models/cnn_{}e.h5'.format(epochs))

print("Model took %0.2f seconds to train"%(end - start))

# Saves the logs 
import numpy as np
loss_history = np.array(history.history['loss'])
np.savetxt('results/logs/log_loss_{}e.txt'.format(epochs), loss_history, delimiter = ',')


# Plot the curves
plt.figure(figsize=[8,6])
plt.plot(history.history['loss'],'r',linewidth=3.0)
plt.plot(history.history['val_loss'],'b',linewidth=3.0)
plt.legend(['Training loss', 'Validation Loss'],fontsize=18)
plt.xlabel('Epochs ',fontsize=16)
plt.ylabel('Loss',fontsize=16)
plt.title('Loss Curves',fontsize=16)

plt.savefig('results/img/cnn_loss_{}e.png'.format(epochs))

plt.figure(figsize=[8,6])
plt.plot(history.history['acc'],'r',linewidth=3.0)
plt.plot(history.history['val_acc'],'b',linewidth=3.0)
plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)
plt.xlabel('Epochs ',fontsize=16)
plt.ylabel('Accuracy',fontsize=16)
plt.title('Accuracy Curves',fontsize=16)

plt.savefig('results/img/cnn_acc_{}e.png'.format(epochs))

plt.show()
